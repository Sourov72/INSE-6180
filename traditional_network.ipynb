{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "\n",
    "lw = 1 # line weight for plt\n",
    "BATCH_SIZE = 32 # Model batch size\n",
    "EPOCHS = 10 # Model number of epoch\n",
    "MODELS_RESULTS={} # store for all model result for both balanced and resampled datasets\n",
    "n_classes=10\n",
    "num_columns = 42  # Number of columns in df\n",
    "regularizers=tf.keras.regularizers.l2(0.001)\n",
    "print(tf.__version__)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "plt.rcParams['savefig.dpi'] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the train and test data dataset from file\n",
    "train_val_csv = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "test_csv = pd.read_csv('UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val=train_val_csv.drop(columns=['id','label'])\n",
    "test=test_csv.drop(columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test with 80 train / 20 test\n",
    "train,val = train_test_split(train_val, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train), 'training examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES=['Normal','Generic', 'Exploits', 'Fuzzers', 'DoS', 'Backdoor', 'Reconnaissance', 'Analysis', 'Shellcode', 'Worms']\n",
    "print(CLASSES)\n",
    "# # five metrics used for evaluation process\n",
    "METRICS = [\n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chart(history,name):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    names =['loss','accuracy']\n",
    "    c=0\n",
    "    for n in names:\n",
    "        c=c+1\n",
    "        n_val = 'val_'+n\n",
    "        hist = history.history[n]\n",
    "        hist_val = history.history[n_val]\n",
    "        plt.subplot(len(names),1,c)\n",
    "        plt.plot(hist, label='Training {}'.format(n))\n",
    "        plt.plot(hist_val, label='Validation {}'.format(n))\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.ylabel(n)\n",
    "        plt.ylim(0.4,1)\n",
    "        plt.title('{} Training and Validation {}'.format(name,n))\n",
    "    plt.xlabel('epoch')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_data_type(data):\n",
    "    # data=data.drop(columns=DROP_COL)\n",
    "    columns=data.columns # get list of columns\n",
    "    unique=data.dtypes.unique() # select one of each dtype\n",
    "    result={'number_col':[],'string_category_col':[],'int_category_col':[],'labels':[]}\n",
    "    for col in columns:\n",
    "        if col=='attack_cat':\n",
    "            temp= result['labels'] # init array\n",
    "        elif data[col].dtypes=='float64':\n",
    "            temp= result['number_col'] # init array\n",
    "        elif data[col].dtypes=='int64':\n",
    "             temp= result['int_category_col'] # init array\n",
    "        else:\n",
    "            temp= result['string_category_col'] # init array\n",
    "        temp.append(col) # append the array\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels=dataframe.pop('attack_cat')\n",
    "    y=tf.keras.utils.to_categorical(labels, num_classes=10)\n",
    "    X=tf.convert_to_tensor(dataframe)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_col_process(data):\n",
    "    normalized_df=(data-data.mean())/data.std()\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_category_col_process(data):\n",
    "    print('process string_category_col')\n",
    "    columns=data.columns.values\n",
    "    for col in columns:\n",
    "        codes, uniques = pd.factorize(data[col])\n",
    "        data[col] = codes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_category_col_process(data):\n",
    "    columns=data.columns.values\n",
    "    for col in columns:\n",
    "        encoder_col = encoder.fit_transform(data[[col]]).toarray()\n",
    "        data[col] = encoder_col\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_process(data):\n",
    "    data['attack_cat'] = data['attack_cat'].map(CLASSES.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,data_types):\n",
    "    result= df.copy()\n",
    "    for name in data_types:\n",
    "        print(name)\n",
    "        types = data_types[name]\n",
    "        selected_df = df[types]\n",
    "        if name =='number_col':\n",
    "            data = number_col_process(selected_df)\n",
    "        if name =='int_category_col':\n",
    "            data = int_category_col_process(selected_df)\n",
    "        if name =='string_category_col':\n",
    "            data = string_category_col_process(selected_df)\n",
    "        if name =='labels':\n",
    "            data = labels_process(selected_df)\n",
    "        for tp in types:\n",
    "            result[tp]=data[tp]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy();\n",
    "val_df = val.copy();\n",
    "test_df = test.copy();\n",
    "# seperate the structured data into individal type\n",
    "data_types = group_by_data_type(train_df) # return result from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fix, compyling and visualisation\n",
    "# TRADITIONAL-NETWORK\n",
    "df = train_df.copy()\n",
    "_ds= process_data(df,data_types)\n",
    "X_train,y_train= df_to_dataset(_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_df.copy()\n",
    "_ds= process_data(df,data_types)\n",
    "X_val,y_val= df_to_dataset(_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df.copy()\n",
    "_ds= process_data(df,data_types)\n",
    "X_test,y_test= df_to_dataset(_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load some data\n",
    "def build_model(hp):\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Input layer for numeric data\n",
    "    inputs = keras.Input(shape=(42,), name='inputs')\n",
    "\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
    "    x = layers.Dense(hp_units_1,activation='relu',kernel_regularizer=regularizers)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=512, step=32)\n",
    "    x = layers.Dense(units=hp_units_2,activation='relu',kernel_regularizer=regularizers)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    hp_units_3 = hp.Int('units_3', min_value=32, max_value=512, step=32)\n",
    "    x = layers.Dense(units=hp_units_3,activation='relu',kernel_regularizer=regularizers)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    output = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs,output)\n",
    "    print('MODAL-SUMMARY')\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss=keras.losses.CategoricalCrossentropy(), metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRADITIONAL-NETWORK')\n",
    "name='TRADITIONAL-NETWORK'\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "print('fit model for:{}_____________________________________________________________________________________________________________'.format(name))\n",
    "MODELS_RESULTS[name]={}\n",
    "project_name='HYPERPARAM_'+name\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=5,\n",
    "                     factor=3,\n",
    "                     directory='hyperparam_dir',\n",
    "                     project_name=project_name)\n",
    "print('----')\n",
    "#     early stoppping if val_loss is behaving poorly\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "#     hyperparameter search based on 50 epochs\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=[X_val,y_val], callbacks=[stop_early])\n",
    "    # Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "print('----')\n",
    "history = model.fit(X_train,y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=[X_val,y_val])\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "history = hypermodel.fit(X_train,y_train, batch_size=BATCH_SIZE, epochs=best_epoch, validation_data=[X_val,y_val])\n",
    "print('evaluation result model for:{} on TRAIN_________________________________________________________'.format(name))\n",
    "loss,accuracy,precision,recall,auc,prc = hypermodel.evaluate(X_train,y_train)\n",
    "MODELS_RESULTS[name]['train']={'loss':loss,'accuracy':accuracy,'precision':precision,'recall':recall,'auc':auc,'prc':prc}\n",
    "print('loss:{} -accuracy:{} - precision:{} - recall:{} - auc:{} - prc:{}'.format(loss,accuracy,precision,recall,auc,prc))\n",
    "print('----')\n",
    "print('----')\n",
    "print('evaluation result model for:{} on VALIDATION________________________________________________________________________________'.format(name))\n",
    "loss,accuracy,precision,recall,auc,prc = hypermodel.evaluate(X_val,y_val)\n",
    "MODELS_RESULTS[name]['validation']={'loss':loss,'accuracy':accuracy,'precision':precision,'recall':recall,'auc':auc,'prc':prc}\n",
    "print('loss:{} -accuracy:{} - precision:{} - recall:{} - auc:{} - prc:{}'.format(loss,accuracy,precision,recall,auc,prc))\n",
    "print('----')\n",
    "print('----')\n",
    "print('evaluation result model for:{} on TEST________________________________________________________________________________'.format(name))\n",
    "loss,accuracy,precision,recall,auc,prc = hypermodel.evaluate(X_test,y_test)\n",
    "MODELS_RESULTS[name]['test']={'loss':loss,'accuracy':accuracy,'precision':precision,'recall':recall,'auc':auc,'prc':prc}\n",
    "print('loss:{} -accuracy:{} - precision:{} - recall:{} - auc:{} - prc:{}'.format(loss,accuracy,precision,recall,auc,prc))\n",
    "print('----')\n",
    "print('----')\n",
    "print('plot:{}_________________________________________________________'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chart(history,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_true, y_pred_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(MODELS_RESULTS['TRADITIONAL-NETWORK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
